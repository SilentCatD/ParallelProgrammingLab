{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBgThS8q8k3"
      },
      "source": [
        "Họ tên: Nguyễn Ngọc Phước\n",
        "\n",
        "MSSV: 19127519"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdrvDrCrnqz"
      },
      "source": [
        "# HW3: Các loại bộ nhớ trong CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXB0wA7yhq9"
      },
      "source": [
        "Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n",
        "`nvcc tên-file.cu -o tên-file-chạy`\n",
        "\n",
        "Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n",
        "Trong đó, 37 chính là compute capability của GPU Tesla K80.\n",
        "\n",
        "Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCkmnirl2xWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06950a8-74c8-40ee-c421-ad1217255f67"
      },
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq1-pmi72yS6"
      },
      "source": [
        "Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n",
        "`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCyT0o8Z7nj"
      },
      "source": [
        "Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbFLx1i4JxIE"
      },
      "source": [
        "!nvcc HW3.cu -o HW3"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZNqZuECjNso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e68809-f308-479c-efa6-ee737633a4af"
      },
      "source": [
        "!./HW3 in.pnm out.pnm 32 32"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.344704 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.331808 ms\n",
            "Error: 0.050429\n",
            "\n",
            "Kernel 3, block size 32x32, grid size 16x16\n",
            "Kernel time: 0.246752 ms\n",
            "Error: 0.258788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFUj14OYUyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe6816b-887c-4a03-8d8a-74d03670428c"
      },
      "source": [
        "!./HW3 in.pnm out.pnm 32 16"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********GPU info**********\n",
            "Name: Tesla T4\n",
            "Compute capability: 7.5\n",
            "Num SMs: 40\n",
            "Max num threads per SM: 1024\n",
            "Max num warps per SM: 32\n",
            "GMEM: 15843721216 bytes\n",
            "CMEM: 65536 bytes\n",
            "L2 cache: 4194304 bytes\n",
            "SMEM / one SM: 65536 bytes\n",
            "****************************\n",
            "\n",
            "Image size (width x height): 512 x 512\n",
            "\n",
            "Kernel 1, block size 32x16, grid size 16x32\n",
            "Kernel time: 0.316544 ms\n",
            "Error: 0.000703\n",
            "\n",
            "Kernel 2, block size 32x16, grid size 16x32\n",
            "Kernel time: 0.298240 ms\n",
            "Error: 0.306432\n",
            "\n",
            "Kernel 3, block size 32x16, grid size 16x32\n",
            "Kernel time: 0.225376 ms\n",
            "Error: 0.450555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XebMjR45-0Io"
      },
      "source": [
        "Qua kết quả trên, ta có thể thấy thời gian thực hiện các hàm kernel có sự chênh lệch rõ rệt, đặc biệt giữa kernel 1 và 3.\n",
        "\n",
        "Lý do cho chuyện này là việc sử dụng các vùng nhớ như SMEM, CMEM.\n",
        "\n",
        "- Khi sử dụng SMEM, thay vì phải truy xuất trực tiếp GMEM, thời gian truy xuất lâu, ta copy vùng GMEM này vào trong SMEM của từng block và thao tác trên đó. Lúc này việc truy xuất khi sử dụng SMEM sẽ nhanh hơn so với GMEM. Kết quả ta thấy được sự chênh lệch về thời gian truy xuất dữ liệu.\n",
        "\n",
        "- Đối với kernel 3, bình thường ta sử dụng vùng nhớ của filter vẫn là trên GMEM, thay vì vậy, ta copy filter vào CMEM. CMEM cache có tốc độ đọc ghi cao hơn so với GMEM, nên ta thấy được sự cải thiện về thời gian truy xuất. Cũng bởi vì filter là dữ liệu const, không đổi trong quá trình chạy chương trình, cũng như việc truy xuất đến vùng nhớ này có tần suất cao, ta thấy việc copy sang CMEM là hợp lý."
      ]
    }
  ]
}